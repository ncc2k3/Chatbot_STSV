import streamlit as st
from langchain.schema import AIMessage, HumanMessage
from chatbot.chatbot import StudentHandbookChatbot
from chatbot.llm_handler import LLMHandler
from chatbot.prompt_templates import get_prompt_template
from config import *

# Kh·ªüi t·∫°o chatbot v√† LLM handler
chatbot = StudentHandbookChatbot(file_path=FILE_PATH, vectorstore_dir=VECTORSTORE_DIR)
llm_handler = LLMHandler()
prompt_template = get_prompt_template()

# Load ho·∫∑c t·∫°o vector store
chatbot.create_or_load_vectorstore()

# Thi·∫øt l·∫≠p giao di·ªán Streamlit
st.set_page_config(page_title="Chatbot - S·ªï Tay Sinh Vi√™n", layout="wide")
st.title("üí¨ Chatbot H·ªèi ƒê√°p - S·ªï Tay Sinh Vi√™n")

# Kh·ªüi t·∫°o session state cho l·ªãch s·ª≠ h·ªôi tho·∫°i v√† tr·∫°ng th√°i x·ª≠ l√Ω
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

if "waiting_for_response" not in st.session_state:
    st.session_state["waiting_for_response"] = False

# Hi·ªÉn th·ªã h·ªôi tho·∫°i
for msg in st.session_state["chat_history"]:
    if isinstance(msg, HumanMessage):
        st.chat_message("üë§").write(msg.content)
    elif isinstance(msg, AIMessage):
        st.chat_message("ü§ñ").write(msg.content)

# Nh·∫≠p c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
if not st.session_state.waiting_for_response:
    prompt = st.chat_input(placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n t·∫°i ƒë√¢y...")
    if prompt:
        # Th√™m c√¢u h·ªèi v√†o l·ªãch s·ª≠
        user_message = HumanMessage(content=prompt)
        st.session_state["chat_history"].append(user_message)
        st.chat_message("üë§").write(prompt)

        # NgƒÉn ng∆∞·ªùi d√πng nh·∫≠p ti·∫øp trong khi ƒëang x·ª≠ l√Ω
        st.session_state.waiting_for_response = True

        # X·ª≠ l√Ω c√¢u h·ªèi
        with st.spinner("ƒêang x·ª≠ l√Ω c√¢u tr·∫£ l·ªùi..."):
            documents = chatbot.query_documents(prompt)

            if not documents:
                answer = "‚ùå Kh√¥ng t√¨m th·∫•y t√†i li·ªáu ph√π h·ª£p. Vui l√≤ng th·ª≠ l·∫°i v·ªõi c√¢u h·ªèi kh√°c."
            else:
                # T·∫°o ng·ªØ c·∫£nh t·ª´ t√†i li·ªáu
                context = chatbot.combine_context(documents)

                # Sinh c√¢u tr·∫£ l·ªùi t·ª´ template
                chat_history_text = "\n".join(
                    f"{'Ng∆∞·ªùi d√πng' if isinstance(msg, HumanMessage) else 'Tr·ª£ l√Ω'}: {msg.content}"
                    for msg in st.session_state["chat_history"]
                )
                answer = llm_handler.generate_answer(
                    context=context,
                    question=prompt,
                    chat_history=chat_history_text,
                    prompt_template=prompt_template,
                )

            # Th√™m c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠
            ai_message = AIMessage(content=answer)
            st.session_state["chat_history"].append(ai_message)
            st.chat_message("ü§ñ").write(answer)

        # Cho ph√©p ng∆∞·ªùi d√πng nh·∫≠p c√¢u h·ªèi m·ªõi
        st.session_state.waiting_for_response = False
